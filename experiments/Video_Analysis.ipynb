{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import os\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "8m_nWdZ4Mwc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = AutoImageProcessor.from_pretrained(\"dima806/facial_emotions_image_detection\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\"dima806/facial_emotions_image_detection\")a"
      ],
      "metadata": {
        "id": "WyOeqnmcMxbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['Sad', 'Disgust', 'Angry', 'Neutral', 'Fear', 'Surprise', 'Happy']"
      ],
      "metadata": {
        "id": "HxSsZ-iKMzGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict emotion from an image\n",
        "def predict_emotion(image):\n",
        "    try:\n",
        "        # Preprocess image for model input\n",
        "        # image = image.convert('RGB')\n",
        "        inputs = processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "        # Get predictions\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Get top 3 emotions with their corresponding scores\n",
        "        softmax_scores = logits.softmax(dim=1)\n",
        "        top_3_scores, top_3_indices = softmax_scores.topk(3, dim=1)\n",
        "\n",
        "        predictions = []\n",
        "        for i in range(3):\n",
        "            emotion = class_names[top_3_indices[0][i].item()]\n",
        "            score = top_3_scores[0][i].item()\n",
        "            predictions.append({\"emotion\": emotion, \"score\": score})\n",
        "\n",
        "        return predictions\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing frame: {e}\")\n",
        "        return []\n",
        "\n",
        "# Process a video file in 10-second chunks\n",
        "def process_video(video_path, chunk_duration=4):\n",
        "    # Check the fps of the video\n",
        "    framespsec = int(cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FPS))\n",
        "    print(f\"FPS: {framespsec}\")\n",
        "    try:\n",
        "        # Open the video file\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            print(f\"Error: Unable to open video {video_path}\")\n",
        "            return\n",
        "\n",
        "        # Calculate frames per chunk\n",
        "        frames_per_chunk = framespsec * chunk_duration\n",
        "        frame_count = 0\n",
        "        chunk_emotions = []\n",
        "\n",
        "        # Read video frames\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Process only every 30th frame\n",
        "            if frame_count % 30 == 0:\n",
        "                # Convert frame from BGR to RGB for PIL\n",
        "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                frame_image = Image.fromarray(frame_rgb)\n",
        "\n",
        "                # Predict emotions for the frame\n",
        "                predictions = predict_emotion(frame_image)\n",
        "                if predictions:\n",
        "                    # Store the most likely emotion from top 3\n",
        "                    chunk_emotions.append(predictions[0]['emotion'])\n",
        "\n",
        "            # Check if we've processed the current chunk\n",
        "            frame_count += 1\n",
        "            if frame_count % frames_per_chunk == 0:\n",
        "                # Analyze the chunk\n",
        "                emotion_counter = Counter(chunk_emotions)\n",
        "                top_2_emotions = emotion_counter.most_common(2)\n",
        "\n",
        "                print(f\"Chunk {frame_count // frames_per_chunk}:\")\n",
        "                for emotion, freq in top_2_emotions:\n",
        "                    print(f\"Emotion: {emotion} | Frequency: {freq}\")\n",
        "\n",
        "                # Reset for the next chunk\n",
        "                chunk_emotions = []\n",
        "\n",
        "        # Handle remaining frames in the last chunk\n",
        "        if chunk_emotions:\n",
        "            emotion_counter = Counter(chunk_emotions)\n",
        "            top_2_emotions = emotion_counter.most_common(2)\n",
        "\n",
        "            print(f\"Chunk {frame_count // frames_per_chunk + 1}:\")\n",
        "            for emotion, freq in top_2_emotions:\n",
        "                print(f\"Emotion: {emotion} | Frequency: {freq}\")\n",
        "\n",
        "        cap.release()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing video {video_path}: {e}\")"
      ],
      "metadata": {
        "id": "Pr1m1M_QAD77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the video file\n",
        "video_file = \"beauty2.mov\"  # Replace with your video file path\n",
        "\n",
        "# Process the video\n",
        "process_video(video_file)\n"
      ],
      "metadata": {
        "id": "zsbwfrVQM3HO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}