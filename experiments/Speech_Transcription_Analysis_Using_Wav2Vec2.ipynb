{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa datasets pyctcdecode"
      ],
      "metadata": {
        "id": "_kWja1PLUo58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Imports**"
      ],
      "metadata": {
        "id": "gkJ2JOotRacx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import librosa\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "\n",
        "# Configuration\n",
        "LANG_ID = \"en\"\n",
        "MODEL_ID = \"jonatasgrosman/wav2vec2-large-xlsr-53-english\"\n",
        "SAMPLES = 10  # Number of samples to process\n",
        "\n",
        "# Load processor and model\n",
        "\n",
        "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID)\n",
        "\n",
        "# Function to process and transcribe the audio files\n",
        "def speech_file_to_array_fn(file_path):\n",
        "    speech_array, sampling_rate = librosa.load(file_path, sr=16_000)  # Load audio file\n",
        "    return speech_array\n",
        "\n",
        "# List all audio files in the directory (ensure they are in .wav or other supported formats)\n",
        "audio_files = [\"./b1.mp3\"]\n",
        "\n",
        "# Process the audio files and transcribe them\n",
        "for i, audio_file in enumerate(audio_files[:SAMPLES]):  # Limiting to the first `SAMPLES` files\n",
        "    # Load and preprocess audio\n",
        "    speech = speech_file_to_array_fn(audio_file)\n",
        "\n",
        "    # Process the input for the model\n",
        "    inputs = processor(speech, sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "    # Get predictions from the model\n",
        "    with torch.no_grad():\n",
        "        logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
        "\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    predicted_sentence = processor.batch_decode(predicted_ids)[0]  # Decode the first sentence\n",
        "\n",
        "    # Print the results\n",
        "    print(\"-\" * 100)\n",
        "    print(\"Audio File:\", audio_file)\n",
        "    print(\"Prediction:\", predicted_sentence)\n"
      ],
      "metadata": {
        "id": "MYMw1gJiRZzm"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}